{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detalles a revisar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mappings MinMaxScaler, StandardScaler, LabelEncoder\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"std_scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "minimax_p = Pipeline([\n",
    "    (\"mmx_scaler\", MinMaxScaler(feature_range = (0,1)))\n",
    "])\n",
    "\n",
    "logit_pipeline = ColumnTransformer([\n",
    "    (\"cont\", num_pipeline, X_cont),\n",
    "    (\"cat\", OneHotEncoder(), X_cat),\n",
    "    (\"poly\", PolynomialFeatures(interaction_only=True), train_cols)\n",
    "])\n",
    "\n",
    "logit_pipeline2 = ColumnTransformer([\n",
    "    (\"cont\", minimax_p, X_cont),\n",
    "    (\"cat\", OneHotEncoder(), X_cat)\n",
    "])\n",
    "\n",
    "pca_pipeline = ColumnTransformer([\n",
    "    (\"cont\", num_pipeline, X_cont),\n",
    "    (\"pcas\", PCA(n_components = 2), X_cuentas)\n",
    "])\n",
    "\n",
    "pca_pipeline2 = ColumnTransformer([\n",
    "    (\"cont\", num_pipeline, X_cuentas),\n",
    "    (\"pcas\", PCA(n_components = 2), X_cuentas)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.pkbuena\n",
    "\n",
    "#y = sigmoid(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[train_cols],y,\n",
    "                                                    test_size=0.25, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline to search for the best combination of PCA truncation\n",
    "# and classifier regularization.\n",
    "pca = PCA()\n",
    "# set the tolerance to a large value to make the example faster\n",
    "stoch = SGDClassifier(random_state=200614)\n",
    "pipe_sgd = Pipeline(steps=[('pca', pca), ('stochasticgd', stoch), ])\n",
    "\n",
    "# Parameters of pipelines can be set using ‘__’ separated parameter names: max_iter=1000, tol=1e-3\n",
    "param_grid = {\n",
    "    'pca__n_components': [1, 2],\n",
    "    'stochasticgd__max_iter': [500,450, 420,400, 350, 330, 300],\n",
    "    'stochasticgd__tol': [1e-3,5e-4,5e-3,5e-2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(pipe_sgd, param_grid,cv = 10, verbose=True, n_jobs=-1)\n",
    "search.fit(X_train_res, y_train_res)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(search, X_train, y_train, cv=5, scoring=\"recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = cross_val_predict(search, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the PCA spectrum\n",
    "pca.fit(X_train)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(6, 6))\n",
    "ax0.plot(np.arange(1, pca.n_components_ + 1),\n",
    "         pca.explained_variance_ratio_, '+', linewidth=2)\n",
    "ax0.set_ylabel('PCA explained variance ratio')\n",
    "\n",
    "ax0.axvline(search.best_estimator_.named_steps['pca'].n_components,\n",
    "            linestyle=':', label='n_components chosen')\n",
    "ax0.legend(prop=dict(size=12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prep = pca_pipeline2.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_prep = pca_pipeline2.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este paso es para balancear entre clases, aunque no es tan necesario\n",
    "\n",
    "sm = SMOTE(random_state = 2)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_res.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
   "source": []
=======
   "source": [
    "# Create first pipeline for base without reducing features.\n",
    "\n",
    "pipe = Pipeline([('classifier' , RandomForestClassifier())])\n",
    "# pipe = Pipeline([('classifier', RandomForestClassifier())])\n",
    "\n",
    "# Create param grid.\n",
    "\n",
    "param_grid = [\n",
    "    #{'classifier' : [LogisticRegression(random_state=20200611,max_iter=350)],\n",
    "     #'classifier__penalty' : [ 'l2'],\n",
    "    #'classifier__C' : np.logspace(-1, 5, 20),\n",
    "    #'classifier__solver' : ['liblinear']}#,\n",
    "    {'classifier' : [RandomForestClassifier(random_state=20200611,criterion=\"entropy\", max_features=\"auto\", oob_score= True\n",
    "                                            )],\n",
    "    'classifier__n_estimators' : list(range(300,441,20)),\n",
    "    'classifier__max_depth' : list(range(7,12,1))\n",
    "    } \n",
    "]"
   ]
>>>>>>> bc29dfa0a19f3eb3ce3ebb2ff677f3e663745fef
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
   "source": []
=======
   "source": [
    "# Create grid search object\n",
    "\n",
    "clf_rf2 = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "best_clf_rf2 = clf_rf2.fit(X_train_res, y_train_res)"
   ]
>>>>>>> bc29dfa0a19f3eb3ce3ebb2ff677f3e663745fef
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
   "source": []
=======
   "source": [
    "best_clf_rf2.best_estimator_.get_params()['classifier']"
   ]
>>>>>>> bc29dfa0a19f3eb3ce3ebb2ff677f3e663745fef
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
   "source": []
=======
   "source": [
    "classes_rf2 = final_rfc.predict(X_test)\n",
    "    \n",
    "accuracy = accuracy_score(classes_rf2, y_test)\n",
    "    \n",
    "balanced_accuracy = balanced_accuracy_score(classes_rf2, y_test)\n",
    "\n",
    "precision = precision_score(classes_rf2, y_test)\n",
    "    \n",
    "average_precision = average_precision_score(classes_rf2, y_test)\n",
    "    \n",
    "#f1_score = f1_score(classes, y_test)\n",
    "    \n",
    "recall = recall_score(classes_rf2, y_test)\n",
    "\n",
    "print (accuracy, balanced_accuracy, precision, average_precision, #f1_score, \n",
    "       recall)"
   ]
>>>>>>> bc29dfa0a19f3eb3ce3ebb2ff677f3e663745fef
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
   "source": []
=======
   "source": [
    "print(classification_report(classes_rf2, y_test))"
   ]
>>>>>>> bc29dfa0a19f3eb3ce3ebb2ff677f3e663745fef
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
